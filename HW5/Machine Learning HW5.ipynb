{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f481367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d73fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGSIZE = (128, 128)\n",
    "CSIZE = 64  # channel size\n",
    "train_path = 'train'\n",
    "test_path = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e13f55b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "GPU Model: NVIDIA GeForce GTX 1060\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: {}'.format(device))\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU Model: {}'.format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d111d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.image_name_list = []\n",
    "        self.label_list = []\n",
    "        for (root, dirs, files) in os.walk(path, topdown=True):\n",
    "            for names in files:\n",
    "                img_name = os.path.join(root, names)\n",
    "                self.image_name_list.append(img_name)\n",
    "                if names[:2] == 'as':\n",
    "                    self.label_list.append(0)\n",
    "                else:\n",
    "                    self.label_list.append(1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_name_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(self.image_name_list[idx])\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        img = transforms.Resize(IMGSIZE)(img)\n",
    "        img = TF.to_tensor(img)\n",
    "        \n",
    "        label = self.label_list[idx]\n",
    "        return img, label\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.image_name_list)\n",
    "    \n",
    "    def get_label_list(self):\n",
    "        return self.label_list\n",
    "    \n",
    "    def get_image_name_list(self):\n",
    "        return self.image_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01183c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 840\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataset(train_path)\n",
    "print(f\"Training data size: {len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65cd3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_conv_layer(conv, activation, mode='fan_out'):\n",
    "    if isinstance(activation, nn.LeakyReLU):\n",
    "        torch.nn.init.kaiming_uniform_(conv.weight, \n",
    "                                       a=activation.negative_slope,\n",
    "                                       nonlinearity='leaky_relu', \n",
    "                                       mode=mode)\n",
    "    elif isinstance(activation, (nn.ReLU, nn.ELU)):\n",
    "        torch.nn.init.kaiming_uniform_(conv.weight,\n",
    "                                       nonlinearity='relu', \n",
    "                                       mode=mode)\n",
    "    else:\n",
    "        pass\n",
    "    if conv.bias != None:\n",
    "        torch.nn.init.zeros_(conv.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2bbd3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resblock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=1, padding=1, activation=nn.LeakyReLU()):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, k_size, stride, padding)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = activation\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, k_size, stride, padding)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        if self.in_channels != self.out_channels:\n",
    "            self.conv = nn.Conv2d(self.in_channels, self.out_channels, 1)\n",
    "            _init_conv_layer(self.conv, self.activation)\n",
    "        \n",
    "        _init_conv_layer(self.conv1, self.activation)\n",
    "        _init_conv_layer(self.conv2, self.activation)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.in_channels != self.out_channels:\n",
    "            residual = self.conv(residual)\n",
    "        x += residual\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a189500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convblock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_size=3, stride=1, padding=1, activation=nn.LeakyReLU()):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, k_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = activation\n",
    "        \n",
    "        _init_conv_layer(self.conv, self.activation)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bcc625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self, channels, in_channels=3, num_class=2):\n",
    "        super().__init__()\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.conv_layer = Convblock(in_channels, channels//2)\n",
    "        self.resblock1 = Resblock(channels//2, channels//2)\n",
    "        self.resblock2 = Resblock(channels//2, channels//2)\n",
    "        self.resblock3 = Resblock(channels//2, channels)\n",
    "        self.resblock4 = Resblock(channels, channels)\n",
    "        self.resblock5 = Resblock(channels, channels*2)\n",
    "        self.resblock6 = Resblock(channels*2, channels*2)\n",
    "        self.resblock7 = Resblock(channels*2, channels*4)\n",
    "        self.resblock8 = Resblock(channels*4, channels*4)\n",
    "        self.adapool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten() \n",
    "        self.linear = nn.Linear(channels*4, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.maxpool(x)   # size = (64, 64)\n",
    "        \n",
    "        x = self.resblock1(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.maxpool(x)   # size = (32, 32)\n",
    "        \n",
    "        x = self.resblock3(x)\n",
    "        x = self.resblock4(x)\n",
    "        x = self.maxpool(x)   # size = (16, 16)\n",
    "        \n",
    "        x = self.resblock5(x)\n",
    "        x = self.resblock6(x)\n",
    "        x = self.maxpool(x)   # size = (8, 8)\n",
    "        \n",
    "        x = self.resblock7(x)\n",
    "        x = self.resblock8(x)\n",
    "        \n",
    "        x = self.adapool(x)   # 256 x 1 x 1\n",
    "        x = self.flatten(x) \n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6faf1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "resnet = Resnet(channels=CSIZE)\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc9aad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2796801\n"
     ]
    }
   ],
   "source": [
    "# Print number of parameters in the model\n",
    "model_parameters = filter(lambda p: p.requires_grad, resnet.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecf705b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare trainig data, optimizer and loss function\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True, pin_memory=True)\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.0001)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9584d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, optimizer):\n",
    "    resnet.train()\n",
    "    for i in range(epoch):\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            img = data[0]\n",
    "            label = data[1]\n",
    "            label = label.unsqueeze(1)\n",
    "            \n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, label.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"Epoch {i+1}, Batch {batch_idx+1}, Loss: {loss}\")\n",
    "    print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7237ab1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1, Loss: 0.7367566823959351\n",
      "Epoch 1, Batch 2, Loss: 0.7460613250732422\n",
      "Epoch 1, Batch 3, Loss: 0.7710763812065125\n",
      "Epoch 1, Batch 4, Loss: 0.6713249683380127\n",
      "Epoch 1, Batch 5, Loss: 0.6784608364105225\n",
      "Epoch 1, Batch 6, Loss: 0.6677800416946411\n",
      "Epoch 1, Batch 7, Loss: 0.7165850400924683\n",
      "Epoch 1, Batch 8, Loss: 0.6877836585044861\n",
      "Epoch 1, Batch 9, Loss: 0.6970653533935547\n",
      "Epoch 1, Batch 10, Loss: 0.7014040946960449\n",
      "Epoch 1, Batch 11, Loss: 0.6718133687973022\n",
      "Epoch 1, Batch 12, Loss: 0.6906275749206543\n",
      "Epoch 1, Batch 13, Loss: 0.7025914788246155\n",
      "Epoch 2, Batch 1, Loss: 0.6931867599487305\n",
      "Epoch 2, Batch 2, Loss: 0.578265905380249\n",
      "Epoch 2, Batch 3, Loss: 0.6194291710853577\n",
      "Epoch 2, Batch 4, Loss: 0.637890636920929\n",
      "Epoch 2, Batch 5, Loss: 0.6919388175010681\n",
      "Epoch 2, Batch 6, Loss: 0.668404221534729\n",
      "Epoch 2, Batch 7, Loss: 0.6677806377410889\n",
      "Epoch 2, Batch 8, Loss: 0.6576529145240784\n",
      "Epoch 2, Batch 9, Loss: 0.6519913673400879\n",
      "Epoch 2, Batch 10, Loss: 0.6311959028244019\n",
      "Epoch 2, Batch 11, Loss: 0.6070479154586792\n",
      "Epoch 2, Batch 12, Loss: 0.6732535362243652\n",
      "Epoch 2, Batch 13, Loss: 0.6340011358261108\n",
      "Epoch 3, Batch 1, Loss: 0.604948878288269\n",
      "Epoch 3, Batch 2, Loss: 0.6642637252807617\n",
      "Epoch 3, Batch 3, Loss: 0.6433874368667603\n",
      "Epoch 3, Batch 4, Loss: 0.6117595434188843\n",
      "Epoch 3, Batch 5, Loss: 0.6701186895370483\n",
      "Epoch 3, Batch 6, Loss: 0.59563148021698\n",
      "Epoch 3, Batch 7, Loss: 0.6814045906066895\n",
      "Epoch 3, Batch 8, Loss: 0.5987633466720581\n",
      "Epoch 3, Batch 9, Loss: 0.5600583553314209\n",
      "Epoch 3, Batch 10, Loss: 0.5670804381370544\n",
      "Epoch 3, Batch 11, Loss: 0.5756273865699768\n",
      "Epoch 3, Batch 12, Loss: 0.6068979501724243\n",
      "Epoch 3, Batch 13, Loss: 0.608917772769928\n",
      "Epoch 4, Batch 1, Loss: 0.5566799640655518\n",
      "Epoch 4, Batch 2, Loss: 0.5158064961433411\n",
      "Epoch 4, Batch 3, Loss: 0.6009482741355896\n",
      "Epoch 4, Batch 4, Loss: 0.5604653358459473\n",
      "Epoch 4, Batch 5, Loss: 0.5420505404472351\n",
      "Epoch 4, Batch 6, Loss: 0.5531920790672302\n",
      "Epoch 4, Batch 7, Loss: 0.605006217956543\n",
      "Epoch 4, Batch 8, Loss: 0.6329989433288574\n",
      "Epoch 4, Batch 9, Loss: 0.5770821571350098\n",
      "Epoch 4, Batch 10, Loss: 0.5104557275772095\n",
      "Epoch 4, Batch 11, Loss: 0.587264895439148\n",
      "Epoch 4, Batch 12, Loss: 0.6112570762634277\n",
      "Epoch 4, Batch 13, Loss: 0.5981897711753845\n",
      "Epoch 5, Batch 1, Loss: 0.5626498460769653\n",
      "Epoch 5, Batch 2, Loss: 0.5588233470916748\n",
      "Epoch 5, Batch 3, Loss: 0.5418821573257446\n",
      "Epoch 5, Batch 4, Loss: 0.4782235026359558\n",
      "Epoch 5, Batch 5, Loss: 0.5616425275802612\n",
      "Epoch 5, Batch 6, Loss: 0.5397944450378418\n",
      "Epoch 5, Batch 7, Loss: 0.586283802986145\n",
      "Epoch 5, Batch 8, Loss: 0.42510706186294556\n",
      "Epoch 5, Batch 9, Loss: 0.5099320411682129\n",
      "Epoch 5, Batch 10, Loss: 0.6361766457557678\n",
      "Epoch 5, Batch 11, Loss: 0.6235709190368652\n",
      "Epoch 5, Batch 12, Loss: 0.6337343454360962\n",
      "Epoch 5, Batch 13, Loss: 0.5045982003211975\n",
      "Epoch 6, Batch 1, Loss: 0.5620566606521606\n",
      "Epoch 6, Batch 2, Loss: 0.5283329486846924\n",
      "Epoch 6, Batch 3, Loss: 0.5458042621612549\n",
      "Epoch 6, Batch 4, Loss: 0.5715336799621582\n",
      "Epoch 6, Batch 5, Loss: 0.5500043630599976\n",
      "Epoch 6, Batch 6, Loss: 0.47464197874069214\n",
      "Epoch 6, Batch 7, Loss: 0.5361722707748413\n",
      "Epoch 6, Batch 8, Loss: 0.5960155725479126\n",
      "Epoch 6, Batch 9, Loss: 0.5498689413070679\n",
      "Epoch 6, Batch 10, Loss: 0.4660056233406067\n",
      "Epoch 6, Batch 11, Loss: 0.4930371046066284\n",
      "Epoch 6, Batch 12, Loss: 0.4628636837005615\n",
      "Epoch 6, Batch 13, Loss: 0.4739118218421936\n",
      "Epoch 7, Batch 1, Loss: 0.4520418047904968\n",
      "Epoch 7, Batch 2, Loss: 0.47988221049308777\n",
      "Epoch 7, Batch 3, Loss: 0.4365261197090149\n",
      "Epoch 7, Batch 4, Loss: 0.5053277015686035\n",
      "Epoch 7, Batch 5, Loss: 0.49755561351776123\n",
      "Epoch 7, Batch 6, Loss: 0.4429410696029663\n",
      "Epoch 7, Batch 7, Loss: 0.37134799361228943\n",
      "Epoch 7, Batch 8, Loss: 0.4944228529930115\n",
      "Epoch 7, Batch 9, Loss: 0.423384428024292\n",
      "Epoch 7, Batch 10, Loss: 0.46014121174812317\n",
      "Epoch 7, Batch 11, Loss: 0.43024295568466187\n",
      "Epoch 7, Batch 12, Loss: 0.4132249653339386\n",
      "Epoch 7, Batch 13, Loss: 0.47175344824790955\n",
      "Epoch 8, Batch 1, Loss: 0.40532809495925903\n",
      "Epoch 8, Batch 2, Loss: 0.35644733905792236\n",
      "Epoch 8, Batch 3, Loss: 0.37872201204299927\n",
      "Epoch 8, Batch 4, Loss: 0.3947930932044983\n",
      "Epoch 8, Batch 5, Loss: 0.36660969257354736\n",
      "Epoch 8, Batch 6, Loss: 0.3418123722076416\n",
      "Epoch 8, Batch 7, Loss: 0.3935774564743042\n",
      "Epoch 8, Batch 8, Loss: 0.31825709342956543\n",
      "Epoch 8, Batch 9, Loss: 0.2261563539505005\n",
      "Epoch 8, Batch 10, Loss: 0.40271979570388794\n",
      "Epoch 8, Batch 11, Loss: 0.3814243674278259\n",
      "Epoch 8, Batch 12, Loss: 0.35688138008117676\n",
      "Epoch 8, Batch 13, Loss: 0.36242997646331787\n",
      "Epoch 9, Batch 1, Loss: 0.22584404051303864\n",
      "Epoch 9, Batch 2, Loss: 0.28980493545532227\n",
      "Epoch 9, Batch 3, Loss: 0.234887033700943\n",
      "Epoch 9, Batch 4, Loss: 0.4443826675415039\n",
      "Epoch 9, Batch 5, Loss: 0.4189276099205017\n",
      "Epoch 9, Batch 6, Loss: 0.22505319118499756\n",
      "Epoch 9, Batch 7, Loss: 0.28343668580055237\n",
      "Epoch 9, Batch 8, Loss: 0.2700553238391876\n",
      "Epoch 9, Batch 9, Loss: 0.2842828333377838\n",
      "Epoch 9, Batch 10, Loss: 0.32045435905456543\n",
      "Epoch 9, Batch 11, Loss: 0.3055766224861145\n",
      "Epoch 9, Batch 12, Loss: 0.26075708866119385\n",
      "Epoch 9, Batch 13, Loss: 0.383619487285614\n",
      "Epoch 10, Batch 1, Loss: 0.25418347120285034\n",
      "Epoch 10, Batch 2, Loss: 0.2818986475467682\n",
      "Epoch 10, Batch 3, Loss: 0.16610267758369446\n",
      "Epoch 10, Batch 4, Loss: 0.26817750930786133\n",
      "Epoch 10, Batch 5, Loss: 0.25396767258644104\n",
      "Epoch 10, Batch 6, Loss: 0.32449284195899963\n",
      "Epoch 10, Batch 7, Loss: 0.22638696432113647\n",
      "Epoch 10, Batch 8, Loss: 0.18990783393383026\n",
      "Epoch 10, Batch 9, Loss: 0.25402945280075073\n",
      "Epoch 10, Batch 10, Loss: 0.24550926685333252\n",
      "Epoch 10, Batch 11, Loss: 0.1829555332660675\n",
      "Epoch 10, Batch 12, Loss: 0.23858597874641418\n",
      "Epoch 10, Batch 13, Loss: 0.23916631937026978\n",
      "Epoch 11, Batch 1, Loss: 0.11088868230581284\n",
      "Epoch 11, Batch 2, Loss: 0.17905639111995697\n",
      "Epoch 11, Batch 3, Loss: 0.17749109864234924\n",
      "Epoch 11, Batch 4, Loss: 0.2870827913284302\n",
      "Epoch 11, Batch 5, Loss: 0.1949705183506012\n",
      "Epoch 11, Batch 6, Loss: 0.24122312664985657\n",
      "Epoch 11, Batch 7, Loss: 0.23048940300941467\n",
      "Epoch 11, Batch 8, Loss: 0.2255496382713318\n",
      "Epoch 11, Batch 9, Loss: 0.2292875349521637\n",
      "Epoch 11, Batch 10, Loss: 0.0877012386918068\n",
      "Epoch 11, Batch 11, Loss: 0.19872824847698212\n",
      "Epoch 11, Batch 12, Loss: 0.2087043672800064\n",
      "Epoch 11, Batch 13, Loss: 0.2206076979637146\n",
      "Epoch 12, Batch 1, Loss: 0.11716995388269424\n",
      "Epoch 12, Batch 2, Loss: 0.19410088658332825\n",
      "Epoch 12, Batch 3, Loss: 0.31666821241378784\n",
      "Epoch 12, Batch 4, Loss: 0.11147141456604004\n",
      "Epoch 12, Batch 5, Loss: 0.1939907670021057\n",
      "Epoch 12, Batch 6, Loss: 0.19576311111450195\n",
      "Epoch 12, Batch 7, Loss: 0.262276828289032\n",
      "Epoch 12, Batch 8, Loss: 0.15473979711532593\n",
      "Epoch 12, Batch 9, Loss: 0.21427997946739197\n",
      "Epoch 12, Batch 10, Loss: 0.258971244096756\n",
      "Epoch 12, Batch 11, Loss: 0.3340315818786621\n",
      "Epoch 12, Batch 12, Loss: 0.25811412930488586\n",
      "Epoch 12, Batch 13, Loss: 0.19665952026844025\n",
      "Epoch 13, Batch 1, Loss: 0.08596715331077576\n",
      "Epoch 13, Batch 2, Loss: 0.19984139502048492\n",
      "Epoch 13, Batch 3, Loss: 0.2621338367462158\n",
      "Epoch 13, Batch 4, Loss: 0.1922338753938675\n",
      "Epoch 13, Batch 5, Loss: 0.16240674257278442\n",
      "Epoch 13, Batch 6, Loss: 0.15306301414966583\n",
      "Epoch 13, Batch 7, Loss: 0.19126400351524353\n",
      "Epoch 13, Batch 8, Loss: 0.2538529932498932\n",
      "Epoch 13, Batch 9, Loss: 0.18966558575630188\n",
      "Epoch 13, Batch 10, Loss: 0.17981016635894775\n",
      "Epoch 13, Batch 11, Loss: 0.16600123047828674\n",
      "Epoch 13, Batch 12, Loss: 0.15809199213981628\n",
      "Epoch 13, Batch 13, Loss: 0.19171571731567383\n",
      "Epoch 14, Batch 1, Loss: 0.14026856422424316\n",
      "Epoch 14, Batch 2, Loss: 0.13715186715126038\n",
      "Epoch 14, Batch 3, Loss: 0.103830486536026\n",
      "Epoch 14, Batch 4, Loss: 0.20903150737285614\n",
      "Epoch 14, Batch 5, Loss: 0.19712308049201965\n",
      "Epoch 14, Batch 6, Loss: 0.20198184251785278\n",
      "Epoch 14, Batch 7, Loss: 0.1561991572380066\n",
      "Epoch 14, Batch 8, Loss: 0.14184004068374634\n",
      "Epoch 14, Batch 9, Loss: 0.14913834631443024\n",
      "Epoch 14, Batch 10, Loss: 0.23644152283668518\n",
      "Epoch 14, Batch 11, Loss: 0.24242261052131653\n",
      "Epoch 14, Batch 12, Loss: 0.23354807496070862\n",
      "Epoch 14, Batch 13, Loss: 0.11876930296421051\n",
      "Epoch 15, Batch 1, Loss: 0.17929425835609436\n",
      "Epoch 15, Batch 2, Loss: 0.13839416205883026\n",
      "Epoch 15, Batch 3, Loss: 0.1884143203496933\n",
      "Epoch 15, Batch 4, Loss: 0.06455235183238983\n",
      "Epoch 15, Batch 5, Loss: 0.13910037279129028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Batch 6, Loss: 0.1522979736328125\n",
      "Epoch 15, Batch 7, Loss: 0.1936066448688507\n",
      "Epoch 15, Batch 8, Loss: 0.11225610971450806\n",
      "Epoch 15, Batch 9, Loss: 0.18638665974140167\n",
      "Epoch 15, Batch 10, Loss: 0.16515979170799255\n",
      "Epoch 15, Batch 11, Loss: 0.17123885452747345\n",
      "Epoch 15, Batch 12, Loss: 0.18873241543769836\n",
      "Epoch 15, Batch 13, Loss: 0.22204682230949402\n",
      "Epoch 16, Batch 1, Loss: 0.1552322506904602\n",
      "Epoch 16, Batch 2, Loss: 0.12986232340335846\n",
      "Epoch 16, Batch 3, Loss: 0.2507876753807068\n",
      "Epoch 16, Batch 4, Loss: 0.10958702862262726\n",
      "Epoch 16, Batch 5, Loss: 0.10480420291423798\n",
      "Epoch 16, Batch 6, Loss: 0.1031384989619255\n",
      "Epoch 16, Batch 7, Loss: 0.17952904105186462\n",
      "Epoch 16, Batch 8, Loss: 0.1713240146636963\n",
      "Epoch 16, Batch 9, Loss: 0.2350499927997589\n",
      "Epoch 16, Batch 10, Loss: 0.09089444577693939\n",
      "Epoch 16, Batch 11, Loss: 0.2690686583518982\n",
      "Epoch 16, Batch 12, Loss: 0.157575786113739\n",
      "Epoch 16, Batch 13, Loss: 0.2001921534538269\n",
      "Epoch 17, Batch 1, Loss: 0.12718267738819122\n",
      "Epoch 17, Batch 2, Loss: 0.12450407445430756\n",
      "Epoch 17, Batch 3, Loss: 0.09699147194623947\n",
      "Epoch 17, Batch 4, Loss: 0.07199715077877045\n",
      "Epoch 17, Batch 5, Loss: 0.1548607349395752\n",
      "Epoch 17, Batch 6, Loss: 0.15926149487495422\n",
      "Epoch 17, Batch 7, Loss: 0.08972148597240448\n",
      "Epoch 17, Batch 8, Loss: 0.06499610841274261\n",
      "Epoch 17, Batch 9, Loss: 0.1607617884874344\n",
      "Epoch 17, Batch 10, Loss: 0.148644357919693\n",
      "Epoch 17, Batch 11, Loss: 0.07549622654914856\n",
      "Epoch 17, Batch 12, Loss: 0.1921117752790451\n",
      "Epoch 17, Batch 13, Loss: 0.12484429776668549\n",
      "Epoch 18, Batch 1, Loss: 0.10517890006303787\n",
      "Epoch 18, Batch 2, Loss: 0.1731475591659546\n",
      "Epoch 18, Batch 3, Loss: 0.2642245888710022\n",
      "Epoch 18, Batch 4, Loss: 0.061987824738025665\n",
      "Epoch 18, Batch 5, Loss: 0.16445305943489075\n",
      "Epoch 18, Batch 6, Loss: 0.09881867468357086\n",
      "Epoch 18, Batch 7, Loss: 0.11882334202528\n",
      "Epoch 18, Batch 8, Loss: 0.10066066682338715\n",
      "Epoch 18, Batch 9, Loss: 0.1496807187795639\n",
      "Epoch 18, Batch 10, Loss: 0.17296001315116882\n",
      "Epoch 18, Batch 11, Loss: 0.15870094299316406\n",
      "Epoch 18, Batch 12, Loss: 0.13697350025177002\n",
      "Epoch 18, Batch 13, Loss: 0.10487334430217743\n",
      "Epoch 19, Batch 1, Loss: 0.11410538107156754\n",
      "Epoch 19, Batch 2, Loss: 0.0779716968536377\n",
      "Epoch 19, Batch 3, Loss: 0.27582335472106934\n",
      "Epoch 19, Batch 4, Loss: 0.12238623201847076\n",
      "Epoch 19, Batch 5, Loss: 0.10283173620700836\n",
      "Epoch 19, Batch 6, Loss: 0.1822417676448822\n",
      "Epoch 19, Batch 7, Loss: 0.12537452578544617\n",
      "Epoch 19, Batch 8, Loss: 0.10700605809688568\n",
      "Epoch 19, Batch 9, Loss: 0.11632943153381348\n",
      "Epoch 19, Batch 10, Loss: 0.07654030621051788\n",
      "Epoch 19, Batch 11, Loss: 0.09521041810512543\n",
      "Epoch 19, Batch 12, Loss: 0.1580166518688202\n",
      "Epoch 19, Batch 13, Loss: 0.17439806461334229\n",
      "Epoch 20, Batch 1, Loss: 0.0414070263504982\n",
      "Epoch 20, Batch 2, Loss: 0.05955620855093002\n",
      "Epoch 20, Batch 3, Loss: 0.09194191545248032\n",
      "Epoch 20, Batch 4, Loss: 0.18636752665042877\n",
      "Epoch 20, Batch 5, Loss: 0.11512922495603561\n",
      "Epoch 20, Batch 6, Loss: 0.1895759552717209\n",
      "Epoch 20, Batch 7, Loss: 0.1362256407737732\n",
      "Epoch 20, Batch 8, Loss: 0.26860886812210083\n",
      "Epoch 20, Batch 9, Loss: 0.18071390688419342\n",
      "Epoch 20, Batch 10, Loss: 0.07825350016355515\n",
      "Epoch 20, Batch 11, Loss: 0.1563684344291687\n",
      "Epoch 20, Batch 12, Loss: 0.23481246829032898\n",
      "Epoch 20, Batch 13, Loss: 0.12060358375310898\n",
      "Epoch 21, Batch 1, Loss: 0.07985753566026688\n",
      "Epoch 21, Batch 2, Loss: 0.18979617953300476\n",
      "Epoch 21, Batch 3, Loss: 0.17223480343818665\n",
      "Epoch 21, Batch 4, Loss: 0.1381029188632965\n",
      "Epoch 21, Batch 5, Loss: 0.10777110606431961\n",
      "Epoch 21, Batch 6, Loss: 0.2186816930770874\n",
      "Epoch 21, Batch 7, Loss: 0.04740578681230545\n",
      "Epoch 21, Batch 8, Loss: 0.15071386098861694\n",
      "Epoch 21, Batch 9, Loss: 0.15494292974472046\n",
      "Epoch 21, Batch 10, Loss: 0.09875396639108658\n",
      "Epoch 21, Batch 11, Loss: 0.1398259848356247\n",
      "Epoch 21, Batch 12, Loss: 0.11026178300380707\n",
      "Epoch 21, Batch 13, Loss: 0.19427809119224548\n",
      "Epoch 22, Batch 1, Loss: 0.13191473484039307\n",
      "Epoch 22, Batch 2, Loss: 0.0555102601647377\n",
      "Epoch 22, Batch 3, Loss: 0.06590007245540619\n",
      "Epoch 22, Batch 4, Loss: 0.10818704962730408\n",
      "Epoch 22, Batch 5, Loss: 0.10790056735277176\n",
      "Epoch 22, Batch 6, Loss: 0.05904452130198479\n",
      "Epoch 22, Batch 7, Loss: 0.12987247109413147\n",
      "Epoch 22, Batch 8, Loss: 0.310528039932251\n",
      "Epoch 22, Batch 9, Loss: 0.051865942776203156\n",
      "Epoch 22, Batch 10, Loss: 0.10829684883356094\n",
      "Epoch 22, Batch 11, Loss: 0.17249514162540436\n",
      "Epoch 22, Batch 12, Loss: 0.2564694285392761\n",
      "Epoch 22, Batch 13, Loss: 0.1460224986076355\n",
      "Epoch 23, Batch 1, Loss: 0.06362363696098328\n",
      "Epoch 23, Batch 2, Loss: 0.08594494313001633\n",
      "Epoch 23, Batch 3, Loss: 0.04267551004886627\n",
      "Epoch 23, Batch 4, Loss: 0.14702057838439941\n",
      "Epoch 23, Batch 5, Loss: 0.1440950483083725\n",
      "Epoch 23, Batch 6, Loss: 0.050037384033203125\n",
      "Epoch 23, Batch 7, Loss: 0.10660693049430847\n",
      "Epoch 23, Batch 8, Loss: 0.12630414962768555\n",
      "Epoch 23, Batch 9, Loss: 0.1468164622783661\n",
      "Epoch 23, Batch 10, Loss: 0.1417894959449768\n",
      "Epoch 23, Batch 11, Loss: 0.13257119059562683\n",
      "Epoch 23, Batch 12, Loss: 0.23849332332611084\n",
      "Epoch 23, Batch 13, Loss: 0.2548688054084778\n",
      "Epoch 24, Batch 1, Loss: 0.09447158128023148\n",
      "Epoch 24, Batch 2, Loss: 0.09307853132486343\n",
      "Epoch 24, Batch 3, Loss: 0.053933076560497284\n",
      "Epoch 24, Batch 4, Loss: 0.06584104150533676\n",
      "Epoch 24, Batch 5, Loss: 0.10709506273269653\n",
      "Epoch 24, Batch 6, Loss: 0.1615717113018036\n",
      "Epoch 24, Batch 7, Loss: 0.3235836625099182\n",
      "Epoch 24, Batch 8, Loss: 0.0866471603512764\n",
      "Epoch 24, Batch 9, Loss: 0.04134918749332428\n",
      "Epoch 24, Batch 10, Loss: 0.12133903801441193\n",
      "Epoch 24, Batch 11, Loss: 0.142905130982399\n",
      "Epoch 24, Batch 12, Loss: 0.11123209446668625\n",
      "Epoch 24, Batch 13, Loss: 0.15600325167179108\n",
      "Epoch 25, Batch 1, Loss: 0.1296291947364807\n",
      "Epoch 25, Batch 2, Loss: 0.12021888047456741\n",
      "Epoch 25, Batch 3, Loss: 0.1341371238231659\n",
      "Epoch 25, Batch 4, Loss: 0.027034815400838852\n",
      "Epoch 25, Batch 5, Loss: 0.1227569654583931\n",
      "Epoch 25, Batch 6, Loss: 0.055107180029153824\n",
      "Epoch 25, Batch 7, Loss: 0.09373076260089874\n",
      "Epoch 25, Batch 8, Loss: 0.0736929178237915\n",
      "Epoch 25, Batch 9, Loss: 0.18521493673324585\n",
      "Epoch 25, Batch 10, Loss: 0.1099667176604271\n",
      "Epoch 25, Batch 11, Loss: 0.10205821692943573\n",
      "Epoch 25, Batch 12, Loss: 0.16491833329200745\n",
      "Epoch 25, Batch 13, Loss: 0.11798180639743805\n",
      "Epoch 26, Batch 1, Loss: 0.16452495753765106\n",
      "Epoch 26, Batch 2, Loss: 0.08497641980648041\n",
      "Epoch 26, Batch 3, Loss: 0.05144168436527252\n",
      "Epoch 26, Batch 4, Loss: 0.15766488015651703\n",
      "Epoch 26, Batch 5, Loss: 0.10502208769321442\n",
      "Epoch 26, Batch 6, Loss: 0.08926324546337128\n",
      "Epoch 26, Batch 7, Loss: 0.08131428062915802\n",
      "Epoch 26, Batch 8, Loss: 0.07766170799732208\n",
      "Epoch 26, Batch 9, Loss: 0.08138799667358398\n",
      "Epoch 26, Batch 10, Loss: 0.10508693754673004\n",
      "Epoch 26, Batch 11, Loss: 0.12137912958860397\n",
      "Epoch 26, Batch 12, Loss: 0.15311956405639648\n",
      "Epoch 26, Batch 13, Loss: 0.11735799163579941\n",
      "Epoch 27, Batch 1, Loss: 0.04265197366476059\n",
      "Epoch 27, Batch 2, Loss: 0.14050012826919556\n",
      "Epoch 27, Batch 3, Loss: 0.06643711775541306\n",
      "Epoch 27, Batch 4, Loss: 0.09819698333740234\n",
      "Epoch 27, Batch 5, Loss: 0.04628593102097511\n",
      "Epoch 27, Batch 6, Loss: 0.061186280101537704\n",
      "Epoch 27, Batch 7, Loss: 0.12263379991054535\n",
      "Epoch 27, Batch 8, Loss: 0.09360700100660324\n",
      "Epoch 27, Batch 9, Loss: 0.15457528829574585\n",
      "Epoch 27, Batch 10, Loss: 0.1099262461066246\n",
      "Epoch 27, Batch 11, Loss: 0.13478462398052216\n",
      "Epoch 27, Batch 12, Loss: 0.1068066954612732\n",
      "Epoch 27, Batch 13, Loss: 0.15518024563789368\n",
      "Epoch 28, Batch 1, Loss: 0.07736836373806\n",
      "Epoch 28, Batch 2, Loss: 0.08391587436199188\n",
      "Epoch 28, Batch 3, Loss: 0.09924972802400589\n",
      "Epoch 28, Batch 4, Loss: 0.0488862507045269\n",
      "Epoch 28, Batch 5, Loss: 0.09329085797071457\n",
      "Epoch 28, Batch 6, Loss: 0.047739870846271515\n",
      "Epoch 28, Batch 7, Loss: 0.10837417840957642\n",
      "Epoch 28, Batch 8, Loss: 0.11929047852754593\n",
      "Epoch 28, Batch 9, Loss: 0.14192959666252136\n",
      "Epoch 28, Batch 10, Loss: 0.07987863570451736\n",
      "Epoch 28, Batch 11, Loss: 0.14673924446105957\n",
      "Epoch 28, Batch 12, Loss: 0.1779143512248993\n",
      "Epoch 28, Batch 13, Loss: 0.05917191505432129\n",
      "Epoch 29, Batch 1, Loss: 0.11801886558532715\n",
      "Epoch 29, Batch 2, Loss: 0.1724497526884079\n",
      "Epoch 29, Batch 3, Loss: 0.16808713972568512\n",
      "Epoch 29, Batch 4, Loss: 0.0508744977414608\n",
      "Epoch 29, Batch 5, Loss: 0.09915370494127274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Batch 6, Loss: 0.09646086394786835\n",
      "Epoch 29, Batch 7, Loss: 0.08886697888374329\n",
      "Epoch 29, Batch 8, Loss: 0.17932626605033875\n",
      "Epoch 29, Batch 9, Loss: 0.11290422081947327\n",
      "Epoch 29, Batch 10, Loss: 0.04426845908164978\n",
      "Epoch 29, Batch 11, Loss: 0.06737367808818817\n",
      "Epoch 29, Batch 12, Loss: 0.11213946342468262\n",
      "Epoch 29, Batch 13, Loss: 0.16664724051952362\n",
      "Epoch 30, Batch 1, Loss: 0.06048097461462021\n",
      "Epoch 30, Batch 2, Loss: 0.07015751302242279\n",
      "Epoch 30, Batch 3, Loss: 0.10599521547555923\n",
      "Epoch 30, Batch 4, Loss: 0.18164095282554626\n",
      "Epoch 30, Batch 5, Loss: 0.0610169917345047\n",
      "Epoch 30, Batch 6, Loss: 0.07322242856025696\n",
      "Epoch 30, Batch 7, Loss: 0.04322653263807297\n",
      "Epoch 30, Batch 8, Loss: 0.08620115369558334\n",
      "Epoch 30, Batch 9, Loss: 0.1755165308713913\n",
      "Epoch 30, Batch 10, Loss: 0.12804582715034485\n",
      "Epoch 30, Batch 11, Loss: 0.10941536724567413\n",
      "Epoch 30, Batch 12, Loss: 0.09609169512987137\n",
      "Epoch 30, Batch 13, Loss: 0.1247216984629631\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "train(model=resnet, epoch=30, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0735052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    result = []\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            img = data[0]\n",
    "            label = data[1]\n",
    "            label = label.unsqueeze(1)\n",
    "            \n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            pred = model(img)\n",
    "            if pred > 0.5:\n",
    "                pred = 1\n",
    "            else:\n",
    "                pred = 0\n",
    "            \n",
    "            result.append(pred)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7efe978",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageDataset(train_path)\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8cfb210",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = validate(resnet, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d482373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix to better understand the model\n",
    "def plot_confusion_matrix(result):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    cm = metrics.confusion_matrix(train_data.get_label_list(), result)\n",
    "    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square=True, cmap='Blues_r')\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ca47eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf8c6dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9630952380952381\n"
     ]
    }
   ],
   "source": [
    "# Calculate the area under the receiver operating characteristic\n",
    "auroc = metrics.roc_auc_score(train_data.get_label_list(), result)\n",
    "print(f\"AUROC: {auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1ee9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's weight\n",
    "torch.save({'model_state_dict': resnet.state_dict()}, 'elephant.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79f59f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the model from previously saved weight for inference\n",
    "model = Resnet(64)\n",
    "weight = torch.load('elephant.h5')\n",
    "model.load_state_dict(weight['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1a13e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ImageDataset(test_path)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9ae1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify test data and write the prediction into a csv file\n",
    "result = validate(resnet, test_loader)\n",
    "fields = ['ID', 'result']\n",
    "rows = list(zip([x[5:9] for x in test_data.get_image_name_list()], result))\n",
    "filename = 'elephant.csv'\n",
    "with open(filename, 'w' , newline='') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(fields)\n",
    "    csvwriter.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b6628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
